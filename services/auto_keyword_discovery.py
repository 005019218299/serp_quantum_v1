#!/usr/bin/env python3
"""
Auto Keyword Discovery - T·ª± ƒë·ªông ph√°t hi·ªán keyword trending worldwide
Multi-language, Multi-region Keyword Intelligence System
"""

import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, List, Set
import json
import re
from collections import defaultdict
import random

class AutoKeywordDiscovery:
    def __init__(self):
        self.trending_sources = {
            'google_trends': 'https://trends.google.com/trends/api/dailytrends',
            'twitter_trends': 'https://api.twitter.com/1.1/trends/place.json',
            'reddit_trending': 'https://www.reddit.com/r/all/hot.json',
            'news_apis': ['newsapi.org', 'currentsapi.services']
        }
        
        self.discovered_keywords = defaultdict(list)
        self.keyword_scores = {}
        
        # Multi-language support
        self.languages = {
            'en': {'regions': ['US', 'GB', 'AU', 'CA'], 'weight': 1.0},
            'es': {'regions': ['ES', 'MX', 'AR', 'CO'], 'weight': 0.9},
            'fr': {'regions': ['FR', 'CA', 'BE', 'CH'], 'weight': 0.8},
            'de': {'regions': ['DE', 'AT', 'CH'], 'weight': 0.8},
            'zh': {'regions': ['CN', 'TW', 'HK', 'SG'], 'weight': 1.2},
            'ja': {'regions': ['JP'], 'weight': 1.1},
            'ko': {'regions': ['KR'], 'weight': 1.0},
            'vi': {'regions': ['VN'], 'weight': 0.7},
            'th': {'regions': ['TH'], 'weight': 0.6},
            'id': {'regions': ['ID'], 'weight': 0.6}
        }
    
    async def discover_trending_keywords(self, max_keywords: int = 1000) -> Dict[str, List[str]]:
        """Discover trending keywords across multiple sources and languages"""
        
        print("üîç Starting Global Keyword Discovery...")
        
        all_keywords = defaultdict(list)
        
        # Discover from multiple sources
        tasks = [
            self._discover_from_google_trends(),
            self._discover_from_social_media(),
            self._discover_from_news_sources(),
            self._discover_from_search_suggestions(),
            self._discover_from_competitor_analysis()
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Consolidate results
        for result in results:
            if isinstance(result, dict):
                for lang, keywords in result.items():
                    all_keywords[lang].extend(keywords)
        
        # Score and rank keywords
        ranked_keywords = await self._score_and_rank_keywords(all_keywords, max_keywords)
        
        print(f"‚úÖ Discovered {sum(len(kws) for kws in ranked_keywords.values())} trending keywords")
        
        return ranked_keywords
    
    async def _discover_from_google_trends(self) -> Dict[str, List[str]]:
        """Discover keywords from Google Trends (simulated)"""
        
        print("üìà Discovering from Google Trends...")
        
        # Simulate Google Trends data
        trends_data = {
            'en': [
                'AI chatbot 2024', 'electric vehicles', 'remote work tools',
                'cryptocurrency news', 'climate change solutions', 'space exploration',
                'quantum computing', 'virtual reality games', 'sustainable fashion',
                'mental health apps', 'smart home devices', 'renewable energy'
            ],
            'es': [
                'inteligencia artificial', 'coches el√©ctricos', 'trabajo remoto',
                'criptomonedas', 'cambio clim√°tico', 'exploraci√≥n espacial',
                'computaci√≥n cu√°ntica', 'realidad virtual', 'moda sostenible'
            ],
            'fr': [
                'intelligence artificielle', 'voitures √©lectriques', 'travail √† distance',
                'cryptomonnaies', 'changement climatique', 'exploration spatiale'
            ],
            'de': [
                'k√ºnstliche intelligenz', 'elektroautos', 'homeoffice',
                'kryptow√§hrungen', 'klimawandel', 'weltraumforschung'
            ],
            'zh': [
                '‰∫∫Â∑•Êô∫ËÉΩ', 'ÁîµÂä®Ê±ΩËΩ¶', 'ËøúÁ®ãÂ∑•‰Ωú', 'Âä†ÂØÜË¥ßÂ∏Å', 'Ê∞îÂÄôÂèòÂåñ', 'Â§™Á©∫Êé¢Á¥¢'
            ],
            'ja': [
                '‰∫∫Â∑•Áü•ËÉΩ', 'ÈõªÊ∞óËá™ÂãïËªä', '„É™„É¢„Éº„Éà„ÉØ„Éº„ÇØ', 'ÊöóÂè∑ÈÄöË≤®', 'Ê∞óÂÄôÂ§âÂãï', 'ÂÆáÂÆôÊé¢Êüª'
            ],
            'vi': [
                'tr√≠ tu·ªá nh√¢n t·∫°o', 'xe ƒëi·ªán', 'l√†m vi·ªác t·ª´ xa',
                'ti·ªÅn m√£ h√≥a', 'bi·∫øn ƒë·ªïi kh√≠ h·∫≠u', 'kh√°m ph√° v≈© tr·ª•'
            ]
        }
        
        await asyncio.sleep(1)  # Simulate API delay
        return trends_data
    
    async def _discover_from_social_media(self) -> Dict[str, List[str]]:
        """Discover keywords from social media trends"""
        
        print("üì± Discovering from Social Media...")
        
        # Simulate social media trending topics
        social_trends = {
            'en': [
                'viral TikTok challenge', 'Instagram reels tips', 'Twitter spaces',
                'LinkedIn learning', 'YouTube shorts', 'Facebook marketplace',
                'Discord communities', 'Clubhouse rooms', 'Snapchat filters'
            ],
            'es': [
                'desaf√≠o viral TikTok', 'consejos Instagram reels', 'espacios Twitter',
                'aprendizaje LinkedIn', 'YouTube shorts', 'marketplace Facebook'
            ],
            'fr': [
                'd√©fi viral TikTok', 'conseils Instagram reels', 'espaces Twitter',
                'apprentissage LinkedIn', 'YouTube shorts', 'marketplace Facebook'
            ],
            'vi': [
                'th·ª≠ th√°ch viral TikTok', 'm·∫πo Instagram reels', 'Twitter spaces',
                'h·ªçc LinkedIn', 'YouTube shorts', 'ch·ª£ Facebook'
            ]
        }
        
        await asyncio.sleep(0.8)
        return social_trends
    
    async def _discover_from_news_sources(self) -> Dict[str, List[str]]:
        """Discover keywords from news sources"""
        
        print("üì∞ Discovering from News Sources...")
        
        # Simulate news trending topics
        news_trends = {
            'en': [
                'breaking news today', 'world cup 2024', 'election results',
                'stock market crash', 'new iPhone release', 'COVID variants',
                'climate summit', 'tech earnings', 'space mission'
            ],
            'es': [
                'noticias de √∫ltima hora', 'copa mundial 2024', 'resultados electorales',
                'ca√≠da bolsa valores', 'nuevo iPhone', 'variantes COVID'
            ],
            'fr': [
                'derni√®res nouvelles', 'coupe du monde 2024', 'r√©sultats √©lections',
                'krach boursier', 'nouvel iPhone', 'variants COVID'
            ],
            'vi': [
                'tin t·ª©c m·ªõi nh·∫•t', 'world cup 2024', 'k·∫øt qu·∫£ b·∫ßu c·ª≠',
                's·ª•p ƒë·ªï ch·ª©ng kho√°n', 'iPhone m·ªõi', 'bi·∫øn th·ªÉ COVID'
            ]
        }
        
        await asyncio.sleep(1.2)
        return news_trends
    
    async def _discover_from_search_suggestions(self) -> Dict[str, List[str]]:
        """Discover keywords from search suggestions"""
        
        print("üîé Discovering from Search Suggestions...")
        
        # Simulate search suggestion data
        suggestion_keywords = {
            'en': [
                'how to make money online', 'best laptop 2024', 'healthy recipes',
                'workout at home', 'learn programming', 'travel destinations',
                'investment tips', 'online courses', 'job interview tips'
            ],
            'es': [
                'c√≥mo ganar dinero online', 'mejor laptop 2024', 'recetas saludables',
                'ejercicio en casa', 'aprender programaci√≥n', 'destinos viaje'
            ],
            'vi': [
                'c√°ch ki·∫øm ti·ªÅn online', 'laptop t·ªët nh·∫•t 2024', 'c√¥ng th·ª©c n·∫•u ƒÉn',
                't·∫≠p th·ªÉ d·ª•c t·∫°i nh√†', 'h·ªçc l·∫≠p tr√¨nh', 'ƒëi·ªÉm du l·ªãch'
            ]
        }
        
        await asyncio.sleep(0.5)
        return suggestion_keywords
    
    async def _discover_from_competitor_analysis(self) -> Dict[str, List[str]]:
        """Discover keywords from competitor analysis"""
        
        print("üéØ Discovering from Competitor Analysis...")
        
        # Simulate competitor keyword data
        competitor_keywords = {
            'en': [
                'SEO tools comparison', 'digital marketing strategy', 'content creation',
                'social media management', 'email marketing', 'web analytics',
                'conversion optimization', 'brand awareness', 'customer retention'
            ],
            'es': [
                'comparaci√≥n herramientas SEO', 'estrategia marketing digital', 'creaci√≥n contenido',
                'gesti√≥n redes sociales', 'email marketing', 'anal√≠tica web'
            ],
            'vi': [
                'so s√°nh c√¥ng c·ª• SEO', 'chi·∫øn l∆∞·ª£c marketing s·ªë', 't·∫°o n·ªôi dung',
                'qu·∫£n l√Ω m·∫°ng x√£ h·ªôi', 'email marketing', 'ph√¢n t√≠ch web'
            ]
        }
        
        await asyncio.sleep(1.5)
        return competitor_keywords
    
    async def _score_and_rank_keywords(self, all_keywords: Dict[str, List[str]], 
                                     max_keywords: int) -> Dict[str, List[str]]:
        """Score and rank keywords by relevance and potential"""
        
        print("üìä Scoring and ranking keywords...")
        
        ranked_keywords = {}
        
        for language, keywords in all_keywords.items():
            # Remove duplicates
            unique_keywords = list(set(keywords))
            
            # Score keywords
            scored_keywords = []
            for keyword in unique_keywords:
                score = self._calculate_keyword_score(keyword, language)
                scored_keywords.append((keyword, score))
            
            # Sort by score and limit
            scored_keywords.sort(key=lambda x: x[1], reverse=True)
            
            # Get language weight
            lang_weight = self.languages.get(language, {}).get('weight', 1.0)
            max_for_lang = int(max_keywords * lang_weight / 10)  # Distribute based on weight
            
            ranked_keywords[language] = [kw[0] for kw in scored_keywords[:max_for_lang]]
        
        return ranked_keywords
    
    def _calculate_keyword_score(self, keyword: str, language: str) -> float:
        """Calculate keyword score based on multiple factors"""
        
        score = 0.0
        
        # Length factor (prefer 2-4 words)
        word_count = len(keyword.split())
        if 2 <= word_count <= 4:
            score += 1.0
        elif word_count == 1 or word_count == 5:
            score += 0.5
        
        # Commercial intent keywords
        commercial_terms = ['buy', 'best', 'review', 'price', 'cheap', 'discount', 
                          'comprar', 'mejor', 'precio', 'barato', 'descuento',
                          'acheter', 'meilleur', 'prix', 'pas cher', 'remise',
                          'mua', 't·ªët nh·∫•t', 'gi√°', 'r·∫ª', 'gi·∫£m gi√°']
        
        if any(term in keyword.lower() for term in commercial_terms):
            score += 1.5
        
        # Trending indicators
        trending_terms = ['2024', '2025', 'new', 'latest', 'trending', 'viral',
                         'nuevo', '√∫ltimo', 'tendencia', 'viral',
                         'nouveau', 'dernier', 'tendance', 'viral',
                         'm·ªõi', 'm·ªõi nh·∫•t', 'xu h∆∞·ªõng', 'viral']
        
        if any(term in keyword.lower() for term in trending_terms):
            score += 1.2
        
        # Technology/AI keywords (high value)
        tech_terms = ['AI', 'artificial intelligence', 'machine learning', 'blockchain',
                     'IA', 'inteligencia artificial', 'aprendizaje autom√°tico',
                     'tr√≠ tu·ªá nh√¢n t·∫°o', 'h·ªçc m√°y', 'blockchain']
        
        if any(term in keyword.lower() for term in tech_terms):
            score += 2.0
        
        # Language weight
        lang_weight = self.languages.get(language, {}).get('weight', 1.0)
        score *= lang_weight
        
        return score
    
    async def get_personalized_keywords(self, user_profile: Dict) -> List[str]:
        """Get personalized keywords based on user profile"""
        
        user_language = user_profile.get('language', 'en')
        user_interests = user_profile.get('interests', [])
        user_industry = user_profile.get('industry', 'general')
        
        # Get base trending keywords
        trending = await self.discover_trending_keywords(max_keywords=500)
        base_keywords = trending.get(user_language, [])
        
        # Filter by interests
        personalized = []
        for keyword in base_keywords:
            keyword_lower = keyword.lower()
            
            # Match user interests
            if any(interest.lower() in keyword_lower for interest in user_interests):
                personalized.append(keyword)
            
            # Match industry
            if user_industry.lower() in keyword_lower:
                personalized.append(keyword)
        
        # Add some general trending keywords
        personalized.extend(base_keywords[:20])
        
        # Remove duplicates and limit
        return list(set(personalized))[:100]
    
    async def continuous_keyword_monitoring(self, interval_hours: int = 6):
        """Continuously monitor and update trending keywords"""
        
        print(f"üîÑ Starting continuous keyword monitoring (every {interval_hours}h)...")
        
        while True:
            try:
                # Discover new keywords
                new_keywords = await self.discover_trending_keywords()
                
                # Update keyword database
                timestamp = datetime.now().isoformat()
                
                for language, keywords in new_keywords.items():
                    self.discovered_keywords[language] = keywords
                    
                    # Store in database (simulated)
                    print(f"üíæ Updated {len(keywords)} keywords for {language}")
                
                print(f"‚úÖ Keyword monitoring cycle completed at {timestamp}")
                
                # Wait for next cycle
                await asyncio.sleep(interval_hours * 3600)
                
            except Exception as e:
                print(f"‚ùå Keyword monitoring error: {e}")
                await asyncio.sleep(300)  # Wait 5 minutes on error

# Demo usage
async def demo_keyword_discovery():
    """Demo auto keyword discovery"""
    
    discovery = AutoKeywordDiscovery()
    
    # Discover trending keywords
    trending_keywords = await discovery.discover_trending_keywords(max_keywords=200)
    
    print("\nüåç Global Trending Keywords:")
    for language, keywords in trending_keywords.items():
        print(f"\nüìç {language.upper()} ({len(keywords)} keywords):")
        for i, keyword in enumerate(keywords[:5], 1):
            print(f"   {i}. {keyword}")
    
    # Get personalized keywords
    user_profile = {
        'language': 'vi',
        'interests': ['technology', 'AI', 'programming'],
        'industry': 'software'
    }
    
    personalized = await discovery.get_personalized_keywords(user_profile)
    print(f"\nüë§ Personalized Keywords for Vietnamese Tech User:")
    for i, keyword in enumerate(personalized[:10], 1):
        print(f"   {i}. {keyword}")

if __name__ == "__main__":
    asyncio.run(demo_keyword_discovery())